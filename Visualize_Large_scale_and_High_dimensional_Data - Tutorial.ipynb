{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/everythingapplejj/Research-Graph-Embeddings-/blob/JJ/Visualize_Large_scale_and_High_dimensional_Data%20-%20Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P53y_ji26r8G"
      },
      "source": [
        "# Visualize Large-scale and High-dimensional Data\n",
        "\n",
        "In this tutorial, we will learn how to use GraphVite to generate 2D / 3D visualization of high-dimensional data. Visualization can bring us insights about the data, which is quite useful for fields like machine learning and data science.\n",
        "\n",
        "We will first demonstrate the visualization steps with Python code. Then we will show how to invoke fast visualization in command line. Finally we introduce the configuration file and hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "All the code here can be run on Google Colab directly, and results will be displayed in our browser. To run this tutorial,\n",
        "\n",
        "1. At the top-right of the menu bar, choose *connect to hosted runtime*.\n",
        "2. In the menu, choose *Runtime -> Run all*.\n",
        "\n",
        "Since Colab provides only 2 CPU threads and a very economic GPU, the code may take some time to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYo8ZSTjCa-p"
      },
      "source": [
        "Download and install miniconda and GraphVite. This may take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVG43FzysuAy"
      },
      "source": [
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!./Miniconda3-latest-Linux-x86_64.sh -b -p /usr/local -f\n",
        "\n",
        "!conda install -y -c milagraph -c conda-forge graphvite \\\n",
        "  python=3.6 cudatoolkit=10.0\n",
        "!conda install -y wurlitzer ipykernel\n",
        "\n",
        "import site\n",
        "site.addsitedir(\"/usr/local/lib/python3.6/site-packages\")\n",
        "%reload_ext wurlitzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNfUjEOKCSrD"
      },
      "source": [
        "## Python Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aA_v1DMCrLH"
      },
      "source": [
        "First, we import some necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI1yqLJ-evDf"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# The following lines are only needed in Jupyter Notebook\n",
        "from IPython.display import display, Image\n",
        "%matplotlib inline\n",
        "\n",
        "import graphvite as gv\n",
        "import graphvite.application as gap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN08MU13C3-R"
      },
      "source": [
        "We use MNIST dataset for illustration. MNIST is an image dataset that contains 10 categories of hand-written digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb4BRQW8dzQT"
      },
      "source": [
        "images = gv.dataset.mnist.image_data\n",
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(images[i].reshape(28, 28))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXTwOOHeDyXs"
      },
      "source": [
        "Here we visualize the pixel space of mnist images. That is, each image (28x28) is treated as a 784-d vector. There are 70000 images in total."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnqopPmMFOc3",
        "cellView": "both"
      },
      "source": [
        "print(images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVdaWofEGYO1"
      },
      "source": [
        "We create a 2D visualization application in GraphVite.\n",
        "\n",
        "The `load()` step loads the vector data and build a KNNGraph to represent the similarity between vectors. The `build()` step allocates all the resource for training. `train()` is invoked to compute the coordinates in visualization.\n",
        "\n",
        "For now, we just use the default hyperparameters for all steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idRdrdvhd5jd"
      },
      "source": [
        "app = gap.VisualizationApplication(dim=2)\n",
        "app.load(vectors=images)\n",
        "app.build()\n",
        "app.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Up8GB21IWOO"
      },
      "source": [
        "Now we have the visualization coordinates. We can plot them out.\n",
        "\n",
        "In most cases, this will result in 10 clusters. Sometimes there may be one or two more clusters, due to different random seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku738nmKhN06"
      },
      "source": [
        "app.visualization()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gCqJgv5ja0v"
      },
      "source": [
        "A question is, are the clusters corresponding to the categories? We can verify that by coloring the visualization with mnist labels.\n",
        "\n",
        "It looks that the clusters are well aligned with the categories, even if the visualization process isn't supervised by any label. This indicates MNIST is easy to separate in the pixel space, which is consistent with our experience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ7t_APVj2IC"
      },
      "source": [
        "app.visualization(Y=gv.dataset.mnist.label_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uON2orwMpPYA"
      },
      "source": [
        "We can obtain the coordinates by"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF6dV4mWpdoQ"
      },
      "source": [
        "coordinates = app.solver.coordinates\n",
        "print(coordinates.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MQDL3p8M69E"
      },
      "source": [
        "## Command Line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw1GEg4CNbT1"
      },
      "source": [
        "In many cases, we would like to use visualization as an off-the-shelf tool. Fortunately, GraphVite provides us with a convenient command line interface.\n",
        "\n",
        "We just need to store the vectors in a numpy dump (`*.npy`) or a text matrix (`*.txt`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSLsrmgn3WEk"
      },
      "source": [
        "np.savetxt(\"mnist_images.txt\", gv.dataset.mnist.image_data)\n",
        "# an alternative format for vectors\n",
        "np.save(\"mnist_images.npy\", gv.dataset.mnist.image_data)\n",
        "# labels can also be strings\n",
        "np.savetxt(\"mnist_labels.txt\", gv.dataset.mnist.label_data)\n",
        "\n",
        "!graphvite visualize mnist_images.txt --label mnist_labels.txt --save mnist.png --3d\n",
        "\n",
        "display(Image(\"mnist.png\", width=400, height=400))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rATe1fjLOyJT"
      },
      "source": [
        "## Configuration File\n",
        "<a id=\"configuration_file\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF7HdGJqPSfp"
      },
      "source": [
        "GraphVite supports a configuration file interface. This is very useful if we want to customize hyperparameters for the visualization process, or generate multiple plots.\n",
        "\n",
        "The following command creates a configuration scaffold for visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiH_iU1wvRGL"
      },
      "source": [
        "!graphvite new visualization --file my_config.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQnpocZgUHur"
      },
      "source": [
        "In the left pane, we can find `my_config.yaml` in *Files* tab. As Colab doesn't support editing very well, we can edit it in the following cell and then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIlu168aUGwP"
      },
      "source": [
        "%%writefile my_config.yaml\n",
        "application:\n",
        "  visualization\n",
        "\n",
        "resource:\n",
        "  # List of GPU ids. Multiple GPUs will cause unstable results.\n",
        "  gpus: [0]\n",
        "  # Memory limit for each GPU in bytes. Default is all available memory.\n",
        "  gpu_memory_limit: auto\n",
        "  # Number of CPU thread per GPU. Default is all CPUs.\n",
        "  cpu_per_gpu: auto\n",
        "  # Dimension of the embeddings.\n",
        "  dim: 2\n",
        "\n",
        "format:\n",
        "  # String of delimiter characters. Change it if your node name contains blank character.\n",
        "  delimiters: \" \\t\\r\\n\"\n",
        "  # Prefix of comment strings. Change it if you use comment style other than Python.\n",
        "  comment: \"#\"\n",
        "\n",
        "graph:\n",
        "  # Path to vector file. Each line should be one of the following\n",
        "  # [value] [delimiter] [value] [delimiter]... [comment]...\n",
        "  # [comment]...\n",
        "  # For standard datasets, you can specify them by <[dataset].[split]>.\n",
        "  vector_file:\n",
        "  # Number of neighbors for each node. Default is usually reasonable.\n",
        "  num_neighbor: 200\n",
        "  # Perplexity for the neighborhood of each node.\n",
        "  # Typical values are between 5 and 50. Need to be tuned for best results.\n",
        "  # Larger value focuses on global difference and results in larger clusters.\n",
        "  perplexity: 30\n",
        "  # Normalize the input vectors or not. True is recommended.\n",
        "  vector_normalization: true\n",
        "\n",
        "build:\n",
        "  optimizer:\n",
        "    # Optimizer.\n",
        "    type: Adam\n",
        "    # Learning rate. Default is usually reasonable.\n",
        "    lr: 0.5\n",
        "    # Weight decay. Default is usually reasonable.\n",
        "    weight_decay: 1.0e-5\n",
        "    # Learning rate schedule, can be \"linear\" or \"constant\". Linear is recommended.\n",
        "    schedule: linear\n",
        "  # Number of partitions. Auto is recommended.\n",
        "  num_partition: auto\n",
        "  # Number of negative samples per positive sample.\n",
        "  # Larger value results in slower training.\n",
        "  # The performance may be influenced by num_negative * negative_weight.\n",
        "  num_negative: 5\n",
        "  # Batch size of samples in CPU-GPU transfer. Default is recommended.\n",
        "  batch_size: 100000\n",
        "  # Number of batches in a partition block.\n",
        "  # Default is recommended.\n",
        "  episode_size: auto\n",
        "\n",
        "# Comment out this section if not needed.\n",
        "load:\n",
        "  # Path to model file, can be \"*.pkl\".\n",
        "  file_name: visualization.pkl\n",
        "\n",
        "train:\n",
        "  # Model, can be LargeVis.\n",
        "  model: LargeVis\n",
        "  # Number of epochs. Default is recommended.\n",
        "  num_epoch: 50\n",
        "  # Resume training from a loaded model.\n",
        "  resume: false\n",
        "  # Weight of negative samples. Values larger than 10 may cause unstable training.\n",
        "  negative_weight: 3\n",
        "  # Exponent of degrees in negative sampling. Default is recommended.\n",
        "  negative_sample_exponent: 0.75\n",
        "  # Batch size of samples in samplers. Default is recommended.\n",
        "  sample_batch_size: 2000\n",
        "  # Log every n batches.\n",
        "  log_frequency: 1000\n",
        "\n",
        "# Comment out this section if not needed.\n",
        "evaluate:\n",
        "  # Comment out any task if not needed.\n",
        "  - task: visualization\n",
        "    # Path to label file. Each line should be one of the following\n",
        "    # [label] [comment]...\n",
        "    # [comment]...\n",
        "    # The file is assumed to have the same order as input vectors.\n",
        "    file_name:\n",
        "    # Path to save file, can be either \"*.png\" or \"*.pdf\".\n",
        "    # If not provided, show the figure in window.\n",
        "    save_file:\n",
        "    # Size of the figure.\n",
        "    figure_size: 10\n",
        "    # Size of points. Recommend to use figure_size / 5.\n",
        "    scale: 2\n",
        "\n",
        "  # This task only works for dim = 3.\n",
        "  - task: animation\n",
        "    # Path to label file. Each line should be one of the following\n",
        "    # [label] [comment]...\n",
        "    # [comment]...\n",
        "    file_name:\n",
        "    # Path to save file, can be \"*.gif\".\n",
        "    save_file:\n",
        "    # Size of the figure.\n",
        "    figure_size: 5\n",
        "    # Size of points. Recommend to use figure_size / 5.\n",
        "    scale: 1\n",
        "    # Elevation angle. Default is recommended.\n",
        "    elevation: 30\n",
        "    # Number of frames. Default is recommended.\n",
        "    num_frame: 700\n",
        "\n",
        "  - task: hierarchy\n",
        "    # Path to hierarchical label file. Each line should be one of the following\n",
        "    # [label] [delimiter] [label] [delimiter]... [comment]...\n",
        "    # [comment]...\n",
        "    # Labels should be ordered in ascending depth, i.e. the first label corresponds to the root in the hierarchy.\n",
        "    # The file is assumed to have the same order as input vectors.\n",
        "    file_name:\n",
        "    # Target class to be visualized.\n",
        "    target:\n",
        "    # Path to save file, can be \"*.gif\".\n",
        "    save_file:\n",
        "    # Size of the figure.\n",
        "    figure_size: 10\n",
        "    # Size of points. Recommend to use figure_size / 5.\n",
        "    scale: 2\n",
        "    # Duration of each frame in seconds. Default is recommended.\n",
        "    duration: 3\n",
        "\n",
        "# Comment out this section if not needed.\n",
        "save:\n",
        "  # Path to save file, can be \"*.pkl\".\n",
        "  file_name: visualization.pkl\n",
        "  # Save hyperparameters or not.\n",
        "  save_hyperparameter: false"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbQ5yVd2UfRH"
      },
      "source": [
        "Once we are done, we can run our configuration by"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQCJJ9gL5Str"
      },
      "source": [
        "# !graphvite run my_config.yaml --cpu 2 --gpu 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWCxlzPqgCbR"
      },
      "source": [
        "## Hyperparmeters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGRbjxDhVBAu"
      },
      "source": [
        "As showed in Configuration File, there are a bunch of hyperparameters we can custom in GraphVite. Here are a few hyperparameters you may concern for best visualization results, ranked by decreasing importance.\n",
        "\n",
        "1. `perplexity`. It controls the number of nearest neighbors to preserve for each sample in the visualization. In other words, we get larger clusters from larger perplexity. Common values are 10, 30 and 50. Note `perplexity` should be always smaller than `num_neighbor`.\n",
        "\n",
        "2. `weight_decay`. It controls the distance between clusters. This might be useful if we want some beautiful spacing. Common values are 1.0e-4, 1.0e-5 and 1.0e-6."
      ]
    }
  ]
}